{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from gensim import models, corpora\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download('punkt')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversao_termos(texto):\n",
    "    texto = re.sub(\" abc \",\" academia brasileira de ciência \",texto.lower())\n",
    "    texto = re.sub(\" ai \",\" arquitetura da informação \",texto.lower())\n",
    "    texto = re.sub(\" ala \",\" american library association \",texto.lower())\n",
    "    texto = re.sub(\" ala \",\" american library association \",texto.lower())\n",
    "    texto = re.sub(\" american society for information science and Technology \",\" asist \",texto.lower())\n",
    "    texto = re.sub(\" annual review of information science and technology \",\" arist \",texto.lower())\n",
    "    texto = re.sub(\" aoi \",\" arquitetura e organização da informação \",texto.lower())\n",
    "    texto = re.sub(\" associação brasileira de educação em ciência da informação \",\" abecin \",texto.lower())\n",
    "    texto = re.sub(\" associação brasileira de ensino de biblioteconomia e documentação \",\" abebd \",texto.lower())\n",
    "    texto = re.sub(\" associação brasileira de normas técnicas \",\" abnt \",texto.lower())\n",
    "    texto = re.sub(\" associação nacional de pesquisa e pós-graduação em ciência da informação \",\" ancib \",texto.lower())\n",
    "    texto = re.sub(\" base de dados referencial de artigos de periódicos em ciência da informação \",\" brapci \",texto.lower())\n",
    "    texto = re.sub(\" bci \",\" biblioteconomia e ciência da informação \",texto.lower())\n",
    "    texto = re.sub(\" biblioteca digital de teses e dissertações \",\" bdtd \",texto.lower())\n",
    "    texto = re.sub(\" bn \",\" biblioteca nacional \",texto.lower())\n",
    "    texto = re.sub(\" bu \",\" biblioteca universitária \",texto.lower())\n",
    "    texto = re.sub(\" c&t \",\" ciência e tecnologia \",texto.lower())\n",
    "    texto = re.sub(\" cc \",\" ciência da computação \",texto.lower())\n",
    "    texto = re.sub(\" ccn \",\" catálogo coletivo nacional \",texto.lower())\n",
    "    texto = re.sub(\" cdd \",\" classificação decimal de dewey \",texto.lower())\n",
    "    texto = re.sub(\" cdu \",\" classificação decimal universal \",texto.lower())\n",
    "    texto = re.sub(\" cdu \",\" classificação decimal universal \",texto.lower())\n",
    "    texto = re.sub(\" cepe \",\" conselho de extensão e pesquisa \",texto.lower())\n",
    "    texto = re.sub(\" cepe \",\" conselho de extensão e pesquisa \",texto.lower())\n",
    "    texto = re.sub(\" ci \",\" ciência da informação \",texto.lower())\n",
    "    texto = re.sub(\" ci:\",\" ciência da informação \",texto.lower()) \n",
    "    texto = re.sub(\" ci,\",\" ciência da informação \",texto.lower())\n",
    "    texto = re.sub(\" cms \",\" content management system \",texto.lower())\n",
    "    texto = re.sub(\" cne \",\" conselho nacional de educação \",texto.lower())\n",
    "    texto = re.sub(\" conselho nacional de desenvolvimento científico e tecnológico \",\" cnpq \",texto.lower())\n",
    "    texto = re.sub(\" coordenação de aperfeiçoamento de pessoal de nível superior \",\" capes \",texto.lower())\n",
    "    texto = re.sub(\" coordenação de aperfeiçoamento de pessoal de nível superior \",\" capes \",texto.lower())\n",
    "    texto = re.sub(\" crm \",\" customer relationship management \",texto.lower())\n",
    "    texto = re.sub(\" dc \",\" dublin core \",texto.lower())\n",
    "    texto = re.sub(\" descriptive ontology for linguistic and cognitive engineering \",\" dolce \",texto.lower())\n",
    "    texto = re.sub(\" ead \",\" educação à distância \",texto.lower())\n",
    "    texto = re.sub(\" eci \",\" escola de ciência da informação \",texto.lower())\n",
    "    texto = re.sub(\" enade \",\" exame nacional de desempenho \",texto.lower())\n",
    "    texto = re.sub(\" encontro nacional de pesquisa em ciência da informação \",\" enancib \",texto.lower())\n",
    "    texto = re.sub(\" fgv \",\" Fundação Getúlio Vargas \",texto.lower())\n",
    "    texto = re.sub(\" fiocruz \",\" fundação oswaldo cruz \",texto.lower())\n",
    "    texto = re.sub(\" ftp \",\" file transfer protocol \",texto.lower())\n",
    "    texto = re.sub(\" fundação brasileira à pesquisa do estudo de minas gerais \",\" fapemig \",texto.lower())\n",
    "    texto = re.sub(\" fundação brasileira à pesquisa do estudo de são paulo \",\" fapesp \",texto.lower())\n",
    "    texto = re.sub(\" fundação brasileira à pesquisa do estudo do rio de janeiro \",\" faperj \",texto.lower())\n",
    "    texto = re.sub(\" fundação de amparo às pesquisas \",\" faps \",texto.lower())\n",
    "    texto = re.sub(\" gic \",\" gestão da informação e conhecimento \",str(texto.lower()))\n",
    "    texto = re.sub(\" gic \",\" gestão da informação e do conhecimento \",texto.lower())\n",
    "    texto = re.sub(\" gpl \",\" general public licence \",texto.lower())\n",
    "    texto = re.sub(\" hypertext markup language limguagem \",\" html \",texto.lower())\n",
    "    texto = re.sub(\" ia \",\" inteligência artificial \",texto.lower())\n",
    "    texto = re.sub(\" ibpc \",\" instituto brasileiro do patrimônio cultural \",texto.lower())\n",
    "    texto = re.sub(\" ibpc \",\" instituto brasileiro do patrimônio cultural \",texto.lower())\n",
    "    texto = re.sub(\" ics \",\" informação cultura e sociedade \",texto.lower())\n",
    "    texto = re.sub(\" ict \",\" informação, ciência e tecnologia \",texto.lower())\n",
    "    texto = re.sub(\" idh \",\" índice de desenvolvimento humano \",texto.lower())\n",
    "    texto = re.sub(\" ies \",\" instituição de ensino superior \",texto.lower())\n",
    "    texto = re.sub(\" information science and technology abstracts \",\" ista \",texto.lower())\n",
    "    texto = re.sub(\" instituto brasileiro de bibliografia e documentação \",\" ibbd \",texto.lower())\n",
    "    texto = re.sub(\" instituto brasileiro de geografia e estatística \",\" ibge \",texto.lower())\n",
    "    texto = re.sub(\" instituto brasileiro de informação em ciência e tecnologia \",\" ibict \",texto.lower())\n",
    "    texto = re.sub(\" instituto de ciência da informação \",\" ici \",texto.lower())\n",
    "    texto = re.sub(\" instituto nacional de estudos e pesquisas educacionais anísio teixeira \",\" inep \",texto.lower())\n",
    "    texto = re.sub(\" instituto universitário de pesquisa do rio de janeiro \",\" iuoerj \",texto.lower())\n",
    "    texto = re.sub(\" international federation of library associations and institutions \",\" ifla \",texto.lower())\n",
    "    texto = re.sub(\" international standard book number \",\" isbn \",texto.lower())\n",
    "    texto = re.sub(\" international standard serial number \",\" issn \",texto.lower())\n",
    "    texto = re.sub(\" isi \",\" institute for scientific information \",texto.lower())\n",
    "    texto = re.sub(\" iso \",\" international organization for standardization \",texto.lower())\n",
    "    texto = re.sub(\" it \",\" informação e tecnologia \",texto.lower())\n",
    "    texto = re.sub(\" jcr \",\" journal citation reports \",texto.lower())\n",
    "    texto = re.sub(\" jstor \",\" journal storage \",texto.lower())\n",
    "    texto = re.sub(\" kos \",\" sistemas de organização do conhecimento \",texto.lower())\n",
    "    texto = re.sub(\" lc \",\" linguagem cinzenta \",texto.lower())\n",
    "    texto = re.sub(\" ld \",\" linguagem documentária \",texto.lower())\n",
    "    texto = re.sub(\" ldb \",\" lei de diretrizes e bases \",texto.lower())\n",
    "    texto = re.sub(\" library and informations science abstracts \",\" lisa \",texto.lower())\n",
    "    texto = re.sub(\" ln \",\" linguagem natural \",texto.lower())\n",
    "    texto = re.sub(\" lod \",\" linked open data \",texto.lower())\n",
    "    texto = re.sub(\" marc \",\" machine readable cataloging \",texto.lower())\n",
    "    texto = re.sub(\" mdi \",\" multiple document interface \",texto.lower())\n",
    "    texto = re.sub(\" mec \",\" ministério da educação \",texto.lower())\n",
    "    texto = re.sub(\" npd \",\" núcleo de pesquisa e documentação \",texto.lower())\n",
    "    texto = re.sub(\" oai \",\" open archives iniciative \",texto.lower())\n",
    "    texto = re.sub(\" oc \",\" organização do conhecimento \",texto.lower())\n",
    "    texto = re.sub(\" ocr \",\" optical character recognition \",texto.lower())\n",
    "    texto = re.sub(\" oi \",\" organização da informação \",texto.lower())\n",
    "    texto = re.sub(\" ojs \",\" open journal systems \",texto.lower())\n",
    "    texto = re.sub(\" ong \",\" organização não-governamental \",texto.lower())\n",
    "    texto = re.sub(\" onu \",\" organização das nações unidas \",texto.lower())\n",
    "    texto = re.sub(\" organização das nações unidas para a educação e cultura \",\" unesco \",texto.lower())\n",
    "    texto = re.sub(\" osi \",\" open society institute \",texto.lower())\n",
    "    texto = re.sub(\" oui \",\" organização e uso da informação \",texto.lower())\n",
    "    texto = re.sub(\" owl \",\" web ontology language \",texto.lower())\n",
    "    texto = re.sub(\" pln \",\" processamento de linguagem natural \",texto.lower())\n",
    "    texto = re.sub(\" plos \",\" public library of science \",texto.lower())\n",
    "    texto = re.sub(\" poi \",\" produção e organização da informação \",texto.lower())\n",
    "    texto = re.sub(\" pontifícia universidade católica de minas gerais \",\" puc mg \",texto.lower())\n",
    "    texto = re.sub(\" pontifícia universidade católica de são paulo \",\" puc sp \",texto.lower())\n",
    "    texto = re.sub(\" pontifícia universidade católica do rio de janeiro \",\" puc rj \",texto.lower())\n",
    "    texto = re.sub(\" pontifícia universidade católica do rio grande do sul \",\" puc rs \",texto.lower())\n",
    "    texto = re.sub(\" ppg \",\" programa de pós-graduação \",texto.lower())\n",
    "    texto = re.sub(\" programa de pós-graduação em ciência da informação \",\" ppgci \",texto.lower())\n",
    "    texto = re.sub(\" programa de pós-graduação em ciências sociais \",\" ppgcs \",texto.lower())\n",
    "    texto = re.sub(\" programa de pós-graduação em sociologia \",\" ppgs \",texto.lower())\n",
    "    texto = re.sub(\" rc \",\" representação do conhecimento \",texto.lower())\n",
    "    texto = re.sub(\" rdf \",\" resource description framework \",texto.lower())\n",
    "    texto = re.sub(\" ri \",\" recuperação da informação \",texto.lower())\n",
    "    texto = re.sub(\" ri \",\" recuperação da informação \",texto.lower())\n",
    "    texto = re.sub(\" sad \",\" sistema de apoio à decisão \",texto.lower())\n",
    "    texto = re.sub(\" sci \",\" science citation index \",texto.lower())\n",
    "    texto = re.sub(\" scientific electronic library online \",\" scielo\",texto.lower())\n",
    "    texto = re.sub(\" sdr \",\" zona de desenvolvimento real \",texto.lower())\n",
    "    texto = re.sub(\" serviço central de informação bibliográfica \",\" scib \",texto.lower())\n",
    "    texto = re.sub(\" serviço nacional de aprendizagem comercial \",\" senac \",texto.lower())\n",
    "    texto = re.sub(\" serviço nacional de aprendizagem industrial \",\" senai \",texto.lower())\n",
    "    texto = re.sub(\" serviço social da indústria \",\" sesi \",texto.lower())\n",
    "    texto = re.sub(\" serviço social do comércio \",\" sesc \",texto.lower())\n",
    "    texto = re.sub(\" sesi \",\" serviço social da indústria \",texto.lower())\n",
    "    texto = re.sub(\" sibi \",\" sistema integrado de bibliotecas \",texto.lower())\n",
    "    texto = re.sub(\" sig \",\" sistema de informação gerencial \",texto.lower())\n",
    "    texto = re.sub(\" snad \",\" secretária nacional de políticas anti-drogas \",texto.lower())\n",
    "    texto = re.sub(\" snpq \",\" sistema nacional de pós-graduação\",texto.lower())\n",
    "    texto = re.sub(\" soc \",\" sistemas de organização do conhecimento \",texto.lower())\n",
    "    texto = re.sub(\" sri \",\" sistema de recuperação da informação \",texto.lower())\n",
    "    texto = re.sub(\" ssd \",\" sistema de suporte à decisão \",texto.lower())\n",
    "    texto = re.sub(\" tcc \",\" trabalho de conclusão de curso \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal de minas gerais \",\" ufmg \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal de ouro preto \",\" ufop \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal de pernambuco \",\" ufpe \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal de santa caratina \",\" ufsc \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal de são carlos \",\" ufscar \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal de sergipe \",\" ufs \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal de viçosa \",\" ufv \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal do ceará \",\" ufc \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal do estado do rio de janeiro \",\" unirio \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal do maranhão \",\" ufma \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal do pará \",\" ufpa \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal do paraná \",\" ufpr \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal do rio de janeiro \",\" ufrj \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal do rio grande do norte \",\" ufrn \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal do rio grande do sul  \",\" ufrgs \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal fluminense \",\" uff \",texto.lower())\n",
    "    texto = re.sub(\" universidade federal rural do rio de janeiro \",\" ufrrj \",texto.lower())\n",
    "    texto = re.sub(\" uri \",\" uniform resource identifier \",texto.lower())\n",
    "    texto = re.sub(\" world wide web consortium \",\" w3c \",texto.lower())\n",
    "    texto = re.sub(\" xml \",\" extensible markup language \",texto.lower())\n",
    "    texto = re.sub(\" zpd \",\" zona de desenvolvimento proximal \",texto.lower())\n",
    "    texto = re.sub(\"-se\", \"\", texto.lower())\n",
    "    texto = re.sub(\" se \", \"\", texto.lower())\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus pre-processed with conversion of terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converted_data():\n",
    "    path = \"C:/Users/mbrug/Documents/AnacondaRepositorio/topicModelingLDA/dataset/corpus_gt08.txt\"\n",
    "    file = open(path, \"r\", encoding=\"utf-8\")\n",
    "    \n",
    "    data = []\n",
    "    for fileid in file:\n",
    "        document = fileid\n",
    "        document = conversao_termos(document)\n",
    "        \n",
    "        data.append(document)\n",
    "    return data\n",
    "    \n",
    "def quantidade_documentos(data):\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram e Trigram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigramas(words):\n",
    " \n",
    "    bigrams = []\n",
    " \n",
    "    for i in range(0, len(words)):\n",
    "        if (i == len(words)-1):\n",
    "            break\n",
    "        else:\n",
    "            bigrama_obs = words[i] + '_' + words[i+1]\n",
    "            bigrams.append(bigrama_obs)\n",
    " \n",
    "    return bigrams\n",
    "\n",
    "def trigramas(words):\n",
    " \n",
    "    trigrams = []\n",
    " \n",
    "    for i in range(0, len(words)):\n",
    "        if (i == len(words)-2):\n",
    "            break\n",
    "        else:\n",
    "            trigrama_obs = words[i] + '_' + words[i+1] + '_' + words[i+2]\n",
    "            trigrams.append(trigrama_obs)\n",
    " \n",
    "    return trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization e clean text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "    tokenized_text = word_tokenize(text.lower(), language='portuguese')\n",
    "    cleaned_text = [t for t in tokenized_text if t not in stop_words and re.match('[a-zA-Z\\-][a-zA-Z\\-]{2,}', t)]\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of 10 most common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_10_most_common_words(count_data, count_vectorizer):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    total_counts = np.zeros(len(words))\n",
    "    \n",
    "    for t in count_data:\n",
    "        total_counts+=t.toarray()[0]\n",
    "    \n",
    "    count_dict = (zip(words, total_counts))\n",
    "    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:10]\n",
    "    words = [w[0] for w in count_dict]\n",
    "    counts = [w[1] for w in count_dict]\n",
    "    x_pos = np.arange(len(words)) \n",
    "    \n",
    "    plt.figure(2, figsize=(15, 15/1.6180))\n",
    "    plt.subplot(title='As 10 palavras mais comuns na coleção de documentos')\n",
    "    sns.set_context(\"notebook\", font_scale=1.25, rc={\"lines.linewidth\": 2.5})\n",
    "    sns.barplot(x_pos, counts, palette='husl')\n",
    "    plt.xticks(x_pos, words, rotation=90) \n",
    "    plt.xlabel('Palavras')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCloud ():\n",
    "    wordcloud = WordCloud(background_color=\"white\", \n",
    "                      max_words=5000, \n",
    "                      contour_width=3, \n",
    "                      contour_color='steelblue')\n",
    "    return wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Análise Exploratória**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = converted_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(data)\n",
    "df_data['index'] = df_data.index\n",
    "df_data.columns = ['headline_text', 'index']\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_string = ','.join(list(df_data['headline_text'].values))\n",
    "\n",
    "wordcloud = wordCloud()\n",
    "wordcloud.generate(long_string)\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pré-processamento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the conversion of terms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['headline_text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Configuração de StopWords:**\n",
    "\n",
    "Como podemos verificar, a quantidade de stopwords em Português é muito limitada, o que nos força a *setar* mais palavras. Facilita a escolha de novas stopwords, conhecer um pouco mais sobre os documentos que estão separdos para análise - por conta disso, *setamos* também as stopwords em Inglês, pois os documentos possuem algumas palavras irrelevantes em Inglês também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('portuguese'))\n",
    "stop_words_us =  set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_stopwords = ['é','onde','senão','quanto','outros','sobre','ser','ainda','quais','desse','assim','tal','podemos','portanto','pode',\n",
    "                 'tanto','alguns','possível','p.','v','p','-se','se',' se''nesse','nessa','neste','nesta','http','disponível','acesso',\n",
    "                 'sendo','enancib','marília', 'rio','universidade','federal','dessa','estadual','diz','respeito','finais','considerações',\n",
    "                 'desta','belo horizointe','janeiro','fevereiro','março','abril','maio','junho','julho','agosto','setembro','outubro',\n",
    "                 'novembro','dezembro','porto alegre','outro','xix','londrina','paulista','xvii', 'xiii', 'gt-8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.update(new_stopwords)\n",
    "stop_words.update(stop_words_us)\n",
    "new_stopwords_list = set(stop_words)\n",
    "new_stopwords_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and stopwords removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = df_data['headline_text'].map(clean_data)\n",
    "processed_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_string = \"\"\n",
    "\n",
    "for text in processed_docs:\n",
    "    long_string = long_string + \",\".join(list(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(long_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud.generate(long_string)\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 most common works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=new_stopwords_list)\n",
    "count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data = count_vectorizer.fit_transform(df_data['headline_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_10_most_common_words(count_data, count_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(processed_docs)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA using Bag of Words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.LdaMulticore(bow_corpus, \n",
    "                                num_topics=10, \n",
    "                                id2word=dictionary, \n",
    "                                passes=2, \n",
    "                                workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Analysis of the model result**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)\n",
    "pyLDAvis.display(display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluate of LDA model using Bag of Words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[0]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
